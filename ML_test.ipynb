{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO878ttbUiV/FX63ktCDiUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hatewxb/ml-projects/blob/main/ML_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1"
      ],
      "metadata": {
        "id": "WybJON-MUxCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = \"1.xlsx\"\n",
        "data = pd.read_excel(file_path, sheet_name=\"\\u0414\\u0430\\u043d\\u043d\\u044b\\u0435\")\n",
        "\n",
        "# Независимые переменные\n",
        "X = data[[\"Wages\", \"WorkAge\", \"SecEdu\"]]\n",
        "# Целевая переменная\n",
        "y = data[\"SecStudent\"]\n",
        "\n",
        "# Добавляем константу для регрессии\n",
        "X_with_const = sm.add_constant(X)\n",
        "\n",
        "# Строим модель множественной линейной регрессии\n",
        "model = sm.OLS(y, X_with_const).fit()\n",
        "\n",
        "# Проверка мультиколлинеарности\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# Результаты задачи 1\n",
        "print(\"=== Задача 1 ===\")\n",
        "print(\"Множественная линейная регрессия:\")\n",
        "print(model.summary())\n",
        "print(\"\\nПроверка мультиколлинеарности (VIF):\")\n",
        "print(vif_data)\n",
        "\n",
        "# Дополнительный анализ значимости факторов\n",
        "X_reduced = data[[\"Wages\"]]  # Убираем незначимые переменные\n",
        "X_reduced_with_const = sm.add_constant(X_reduced)\n",
        "\n",
        "# Линейная регрессия с одним фактором\n",
        "model_reduced = sm.OLS(y, X_reduced_with_const).fit()\n",
        "print(\"\\nМодель с одним фактором (Wages):\")\n",
        "print(model_reduced.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HetEGXEaHw7T",
        "outputId": "897315eb-fa62-4c38-a36b-940c3e1c37c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Задача 1 ===\n",
            "Множественная линейная регрессия:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:             SecStudent   R-squared:                       0.099\n",
            "Model:                            OLS   Adj. R-squared:                  0.065\n",
            "Method:                 Least Squares   F-statistic:                     2.958\n",
            "Date:                Fri, 24 Jan 2025   Prob (F-statistic):             0.0372\n",
            "Time:                        11:42:42   Log-Likelihood:                -408.76\n",
            "No. Observations:                  85   AIC:                             825.5\n",
            "Df Residuals:                      81   BIC:                             835.3\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        201.0338     26.575      7.565      0.000     148.158     253.910\n",
            "Wages         -0.0004      0.000     -2.594      0.011      -0.001   -9.64e-05\n",
            "WorkAge       -0.0025      0.003     -0.781      0.437      -0.009       0.004\n",
            "SecEdu         0.4888      0.556      0.879      0.382      -0.618       1.595\n",
            "==============================================================================\n",
            "Omnibus:                       12.920   Durbin-Watson:                   2.169\n",
            "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               16.723\n",
            "Skew:                          -0.707   Prob(JB):                     0.000234\n",
            "Kurtosis:                       4.651   Cond. No.                     4.35e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 4.35e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "\n",
            "Проверка мультиколлинеарности (VIF):\n",
            "   Feature       VIF\n",
            "0    Wages  6.548393\n",
            "1  WorkAge  1.900636\n",
            "2   SecEdu  6.439460\n",
            "\n",
            "Модель с одним фактором (Wages):\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:             SecStudent   R-squared:                       0.081\n",
            "Model:                            OLS   Adj. R-squared:                  0.070\n",
            "Method:                 Least Squares   F-statistic:                     7.338\n",
            "Date:                Fri, 24 Jan 2025   Prob (F-statistic):            0.00820\n",
            "Time:                        11:42:42   Log-Likelihood:                -409.58\n",
            "No. Observations:                  85   AIC:                             823.2\n",
            "Df Residuals:                      83   BIC:                             828.0\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        221.4195      8.427     26.274      0.000     204.658     238.181\n",
            "Wages         -0.0004      0.000     -2.709      0.008      -0.001      -0.000\n",
            "==============================================================================\n",
            "Omnibus:                       13.471   Durbin-Watson:                   2.194\n",
            "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               17.019\n",
            "Skew:                          -0.752   Prob(JB):                     0.000202\n",
            "Kurtosis:                       4.596   Cond. No.                     1.38e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.38e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from scipy.stats import pearsonr, f_oneway\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = \"1.xlsx\"  # Укажите путь к файлу\n",
        "main_data = pd.read_excel(file_path, sheet_name=\"Данные\")\n",
        "\n",
        "# 1. Линейная регрессия с проверкой значимости факторов\n",
        "# Логарифмическое преобразование переменных\n",
        "main_data['log_Wages'] = np.log(main_data['Wages'])\n",
        "main_data['log_WorkAge'] = np.log(main_data['WorkAge'])\n",
        "main_data['log_Popul'] = np.log(main_data['Popul'])\n",
        "\n",
        "# Подготовка данных\n",
        "X_transformed = main_data[['log_Wages', 'log_WorkAge', 'SecEdu']].values\n",
        "y = main_data['SecStudent'].values\n",
        "\n",
        "# Добавление константы\n",
        "X_with_const = sm.add_constant(X_transformed)\n",
        "\n",
        "# Линейная регрессия\n",
        "model = sm.OLS(y, X_with_const).fit()\n",
        "regression_summary = model.summary()\n",
        "\n",
        "# 2. Корреляционная матрица (Пирсона)\n",
        "correlation_matrix = np.corrcoef(X_transformed.T, y)[-1, :-1]\n",
        "\n",
        "# 3. Проверка гипотез через ANOVA\n",
        "# Разделение регионов на группы по зарплатам (квантильное разбиение)\n",
        "main_data['Wages_Group'] = pd.qcut(main_data['Wages'], 3, labels=[\"Low\", \"Medium\", \"High\"])\n",
        "groups = [\n",
        "    main_data.loc[main_data['Wages_Group'] == group, 'SecStudent'].dropna()\n",
        "    for group in [\"Low\", \"Medium\", \"High\"]\n",
        "]\n",
        "anova_test = f_oneway(*groups)\n",
        "\n",
        "# 4. Нормализация данных и повторная линейная регрессия\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X_transformed)\n",
        "\n",
        "# Добавление константы\n",
        "X_normalized_with_const = sm.add_constant(X_normalized)\n",
        "\n",
        "# Линейная регрессия на нормализованных данных\n",
        "model_normalized = sm.OLS(y, X_normalized_with_const).fit()\n",
        "normalized_summary = model_normalized.summary()\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"=== Линейная регрессия (оригинальные данные) ===\")\n",
        "print(regression_summary)\n",
        "\n",
        "print(\"\\n=== Корреляция факторов с численностью студентов СПО ===\")\n",
        "print(\"Корреляция с SecStudent:\", correlation_matrix)\n",
        "\n",
        "print(\"\\n=== ANOVA-тест ===\")\n",
        "print(f\"F-статистика: {anova_test.statistic}, p-значение: {anova_test.pvalue}\")\n",
        "\n",
        "print(\"\\n=== Линейная регрессия (нормализованные данные) ===\")\n",
        "print(normalized_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uQQlr5-orER",
        "outputId": "028373b0-9eab-414d-d830-edb9564e7c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Линейная регрессия (оригинальные данные) ===\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.074\n",
            "Model:                            OLS   Adj. R-squared:                  0.040\n",
            "Method:                 Least Squares   F-statistic:                     2.159\n",
            "Date:                Fri, 24 Jan 2025   Prob (F-statistic):             0.0992\n",
            "Time:                        09:46:45   Log-Likelihood:                -409.91\n",
            "No. Observations:                  85   AIC:                             827.8\n",
            "Df Residuals:                      81   BIC:                             837.6\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        423.6572    116.332      3.642      0.000     192.194     655.121\n",
            "x1           -23.8322     10.214     -2.333      0.022     -44.154      -3.510\n",
            "x2             0.8971      3.558      0.252      0.802      -6.182       7.976\n",
            "x3             0.5913      0.562      1.053      0.296      -0.526       1.709\n",
            "==============================================================================\n",
            "Omnibus:                       10.694   Durbin-Watson:                   2.180\n",
            "Prob(Omnibus):                  0.005   Jarque-Bera (JB):               12.430\n",
            "Skew:                          -0.642   Prob(JB):                      0.00200\n",
            "Kurtosis:                       4.365   Cond. No.                     1.67e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.67e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "\n",
            "=== Корреляция факторов с численностью студентов СПО ===\n",
            "Корреляция с SecStudent: [-0.2466007   0.06651568  0.08292561]\n",
            "\n",
            "=== ANOVA-тест ===\n",
            "F-статистика: 4.846718946145472, p-значение: 0.010244704694778664\n",
            "\n",
            "=== Линейная регрессия (нормализованные данные) ===\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.074\n",
            "Model:                            OLS   Adj. R-squared:                  0.040\n",
            "Method:                 Least Squares   F-statistic:                     2.159\n",
            "Date:                Fri, 24 Jan 2025   Prob (F-statistic):             0.0992\n",
            "Time:                        09:46:45   Log-Likelihood:                -409.91\n",
            "No. Observations:                  85   AIC:                             827.8\n",
            "Df Residuals:                      81   BIC:                             837.6\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        200.4000      3.341     59.980      0.000     193.752     207.048\n",
            "x1            -7.9629      3.413     -2.333      0.022     -14.753      -1.173\n",
            "x2             0.8557      3.394      0.252      0.802      -5.897       7.608\n",
            "x3             3.5412      3.364      1.053      0.296      -3.153      10.235\n",
            "==============================================================================\n",
            "Omnibus:                       10.694   Durbin-Watson:                   2.180\n",
            "Prob(Omnibus):                  0.005   Jarque-Bera (JB):               12.430\n",
            "Skew:                          -0.642   Prob(JB):                      0.00200\n",
            "Kurtosis:                       4.365   Cond. No.                         1.23\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = \"path_to_your_file.xlsx\"\n",
        "data = pd.read_excel('1.xlsx', sheet_name=\"Данные\")\n",
        "\n",
        "# ЗАДАЧА 1: Анализ зависимости численности студентов СПО\n",
        "# Выбираем независимые переменные\n",
        "X = data[['Wages', 'WorkAge', 'SecEdu',  ]]\n",
        "y = data['SecStudent']\n",
        "\n",
        "# Добавляем константу для регрессии\n",
        "X_with_const = sm.add_constant(X)\n",
        "\n",
        "# Строим модель множественной линейной регрессии\n",
        "model = sm.OLS(y, X_with_const).fit()\n",
        "\n",
        "# Проверка мультиколлинеарности\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"Множественная линейная регрессия:\")\n",
        "print(model.summary())\n",
        "print(\"\\nПроверка мультиколлинеарности (VIF):\")\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "lwK8zoOQLO6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b19f76-a252-4491-b837-2394c577608b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Множественная линейная регрессия:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:             SecStudent   R-squared:                       0.099\n",
            "Model:                            OLS   Adj. R-squared:                  0.065\n",
            "Method:                 Least Squares   F-statistic:                     2.958\n",
            "Date:                Fri, 24 Jan 2025   Prob (F-statistic):             0.0372\n",
            "Time:                        08:56:35   Log-Likelihood:                -408.76\n",
            "No. Observations:                  85   AIC:                             825.5\n",
            "Df Residuals:                      81   BIC:                             835.3\n",
            "Df Model:                           3                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const        201.0338     26.575      7.565      0.000     148.158     253.910\n",
            "Wages         -0.0004      0.000     -2.594      0.011      -0.001   -9.64e-05\n",
            "WorkAge       -0.0025      0.003     -0.781      0.437      -0.009       0.004\n",
            "SecEdu         0.4888      0.556      0.879      0.382      -0.618       1.595\n",
            "==============================================================================\n",
            "Omnibus:                       12.920   Durbin-Watson:                   2.169\n",
            "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               16.723\n",
            "Skew:                          -0.707   Prob(JB):                     0.000234\n",
            "Kurtosis:                       4.651   Cond. No.                     4.35e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 4.35e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "\n",
            "Проверка мультиколлинеарности (VIF):\n",
            "   Feature       VIF\n",
            "0    Wages  6.548393\n",
            "1  WorkAge  1.900636\n",
            "2   SecEdu  6.439460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " R-squared:                       0.099 указывает, что модель объясняет всего 9.9% вариации в численности студентов СПО, что является низким значением.\n"
      ],
      "metadata": {
        "id": "vnt91TV8TvHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wages/P>|t| : 0.011 средняя зарплата оказалась статистически значимой с Wages/coef: -0.0004  что означает, что с увеличением зарплаты численность студентов СПО снижается."
      ],
      "metadata": {
        "id": "3-Jd6t2GUNDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WorkAge и SecEdu не являются значимыми предикторами  так как p-value > 0.05"
      ],
      "metadata": {
        "id": "0dnexysmUdfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2"
      ],
      "metadata": {
        "id": "pllEvw6PU0Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Балансировка"
      ],
      "metadata": {
        "id": "wL1pf948ofXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = \"path_to_your_file.xlsx\"\n",
        "data = pd.read_excel('1.xlsx', sheet_name=\"Данные\")\n",
        "\n",
        "# 1. Oversampling с помощью SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Проверка распределения классов после SMOTE\n",
        "smote_distribution = y_train_smote.value_counts()\n",
        "\n",
        "# 2. Undersampling для большинства класса\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Проверка распределения классов после undersampling\n",
        "undersample_distribution = y_train_under.value_counts()\n",
        "\n",
        "# 3. Random Forest с учетом дисбаланса классов\n",
        "rf_balanced = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "rf_balanced.fit(X_train, y_train)\n",
        "rf_balanced_pred = rf_balanced.predict(X_test)\n",
        "rf_balanced_report = classification_report(y_test, rf_balanced_pred)\n",
        "rf_balanced_accuracy = accuracy_score(y_test, rf_balanced_pred)\n",
        "\n",
        "# Собираем результаты\n",
        "results_balancing = {\n",
        "    \"SMOTE Class Distribution\": smote_distribution,\n",
        "    \"Undersampling Class Distribution\": undersample_distribution,\n",
        "    \"Random Forest Balanced Report\": rf_balanced_report,\n",
        "    \"Random Forest Balanced Accuracy\": rf_balanced_accuracy,\n",
        "}\n",
        "\n",
        "results_balancing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG5g45DekIA-",
        "outputId": "52023021-a1af-4fc4-89fa-0475109c5f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'SMOTE Class Distribution': HighEduRegion\n",
              " 0    31\n",
              " 1    31\n",
              " Name: count, dtype: int64,\n",
              " 'Undersampling Class Distribution': HighEduRegion\n",
              " 0    28\n",
              " 1    28\n",
              " Name: count, dtype: int64,\n",
              " 'Random Forest Balanced Report': '              precision    recall  f1-score   support\\n\\n           0       0.92      1.00      0.96        12\\n           1       1.00      0.93      0.96        14\\n\\n    accuracy                           0.96        26\\n   macro avg       0.96      0.96      0.96        26\\nweighted avg       0.96      0.96      0.96        26\\n',\n",
              " 'Random Forest Balanced Accuracy': 0.9615384615384616}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполнение"
      ],
      "metadata": {
        "id": "nh8LIBK_ohgd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ6ltMLJLN_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a15d0d-668f-4801-9b7c-7119f096b9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Логистическая регрессия:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83        12\n",
            "           1       1.00      0.64      0.78        14\n",
            "\n",
            "    accuracy                           0.81        26\n",
            "   macro avg       0.85      0.82      0.81        26\n",
            "weighted avg       0.86      0.81      0.80        26\n",
            "\n",
            "Accuracy: 0.8076923076923077\n",
            "\n",
            "Случайный лес:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        12\n",
            "           1       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.96        26\n",
            "   macro avg       0.96      0.96      0.96        26\n",
            "weighted avg       0.96      0.96      0.96        26\n",
            "\n",
            "Accuracy: 0.9615384615384616\n",
            "\n",
            "KMeans кластеры:\n",
            "[1 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "PCA объяснённая дисперсия:\n",
            "[0.37055205 0.22710113]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Загрузка данных\n",
        "file_path = \"path_to_your_file.xlsx\"\n",
        "data = pd.read_excel('1.xlsx', sheet_name=\"Данные\")\n",
        "\n",
        "# ЗАДАЧА 2: Сравнение регионов (вместо федеральных городов добавляем другую категорию)\n",
        "# Добавляем новую категорию (например, регионы с высоким уровнем образования)\n",
        "data['HighEduRegion'] = (data['HighEdu'] > data['HighEdu'].median()).astype(int)\n",
        "\n",
        "# Подготовка данных\n",
        "X_features = data[['Wages', 'HighEdu', 'SecEdu', 'SecStudent', 'HighStudent', 'Popul', 'WorkAge']]\n",
        "y_target = data['HighEduRegion']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Модели для классификации\n",
        "# Логистическая регрессия\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "\n",
        "# Случайный лес\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "# Кластеризация (KMeans)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_features)\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# PCA для визуализации\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"\\nЛогистическая регрессия:\")\n",
        "print(classification_report(y_test, logreg_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, logreg_pred)}\")\n",
        "\n",
        "print(\"\\nСлучайный лес:\")\n",
        "print(classification_report(y_test, rf_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, rf_pred)}\")\n",
        "\n",
        "print(\"\\nKMeans кластеры:\")\n",
        "print(clusters[:10])  # Пример первых 10 кластеров\n",
        "\n",
        "print(\"\\nPCA объяснённая дисперсия:\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Подготовка данных\n",
        "federal_cities = [\"г. Москва\", \"г. Санкт-Петербург\", \"г. Севастополь\"]\n",
        "data[\"IsFederalCity\"] = data[\"Region\"].isin(federal_cities).astype(int)\n",
        "\n",
        "# Выбираем независимые переменные\n",
        "X = data[[\"Wages\", \"HighEdu\", \"SecEdu\", \"SecStudent\", \"HighStudent\", \"Popul\", \"WorkAge\"]]\n",
        "y = data[\"IsFederalCity\"]\n",
        "\n",
        "# Масштабируем данные\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки с учетом стратификации\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Проверяем распределение классов\n",
        "print(\"Распределение классов в обучающей выборке:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Если классы всё ещё несбалансированы, уменьшаем k_neighbors в SMOTE\n",
        "try:\n",
        "    smote = SMOTE(random_state=42, k_neighbors=min(1, y_train.value_counts()[1] - 1))\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "except ValueError:\n",
        "    print(\"SMOTE не может быть применён из-за недостаточного числа наблюдений меньшинства. Используем ручное дублирование.\")\n",
        "    minority_class = X_train[y_train == 1]\n",
        "    majority_class = X_train[y_train == 0]\n",
        "    minority_labels = y_train[y_train == 1]\n",
        "    majority_labels = y_train[y_train == 0]\n",
        "\n",
        "    X_train_balanced = pd.concat([majority_class, minority_class.sample(len(majority_class), replace=True)])\n",
        "    y_train_balanced = pd.concat([majority_labels, minority_labels.sample(len(majority_labels), replace=True)])\n",
        "\n",
        "# Логистическая регрессия\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train_balanced, y_train_balanced)\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Задача 2: Логистическая регрессия ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
        "print(classification_report(y_test, logreg_pred))\n",
        "\n",
        "# Случайный лес\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train_balanced, y_train_balanced)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Задача 2: Случайный лес ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(classification_report(y_test, rf_pred))\n",
        "\n",
        "# KMeans кластеризация\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans_clusters = kmeans.fit_predict(X_scaled)\n",
        "print(\"\\n=== Задача 2: KMeans ===\")\n",
        "print(\"Кластеры первых 10 регионов:\", kmeans_clusters[:10])\n",
        "\n",
        "# PCA для визуализации\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "print(\"\\n=== Задача 2: PCA ===\")\n",
        "print(\"Доля объясненной дисперсии главными компонентами:\", pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc0J-31ZH9yw",
        "outputId": "dadeaa0d-cee1-45e0-ae9d-eba57baa81f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Распределение классов в обучающей выборке:\n",
            "IsFederalCity\n",
            "0    57\n",
            "1     2\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Задача 2: Логистическая регрессия ===\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        25\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00        26\n",
            "   macro avg       1.00      1.00      1.00        26\n",
            "weighted avg       1.00      1.00      1.00        26\n",
            "\n",
            "\n",
            "=== Задача 2: Случайный лес ===\n",
            "Accuracy: 0.9615384615384616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        25\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.96        26\n",
            "   macro avg       0.75      0.98      0.82        26\n",
            "weighted avg       0.98      0.96      0.97        26\n",
            "\n",
            "\n",
            "=== Задача 2: KMeans ===\n",
            "Кластеры первых 10 регионов: [1 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "=== Задача 2: PCA ===\n",
            "Доля объясненной дисперсии главными компонентами: [0.37055205 0.22710113]\n"
          ]
        }
      ]
    }
  ]
}